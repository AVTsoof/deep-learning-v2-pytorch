{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.417022]]), (1, 1))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a single input example (lower-case x)\n",
    "x = np.random.random((1,1))\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min, mean, max\n",
      "[0.0, 0.499, 1.0]\n",
      "[0.0, 1.0, 2.0]\n",
      "[-1.0, -0.001, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# normalizing a value\n",
    "\n",
    "n_examples = 100000\n",
    "d0 = np.random.random((n_examples,1))  # before norm\n",
    "d1 = 2*np.random.random((n_examples,1))  # after scaling (now between 0 and 2.0)\n",
    "d2 = 2*np.random.random((n_examples,1))-1  # after shifting - final norm result\n",
    "\n",
    "print(\"min, mean, max\")\n",
    "print([np.around(d, decimals=3) for d in [d0.min(), d0.mean(), d0.max()]])\n",
    "print([np.around(d, decimals=3) for d in [d1.min(), d1.mean(), d1.max()]])\n",
    "print([np.around(d, decimals=3) for d in [d2.min(), d2.mean(), d2.max()]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.16595599]]), (1, 1))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create normalized input - single example with single node\n",
    "x = 2*np.random.random((1,1))-1\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.44064899]]), (1, 1))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create single node weight\n",
    "w = 2*np.random.random((1,1))-1\n",
    "w, w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.99977125]]), (1, 1))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create single node bias\n",
    "b = 2*np.random.random((1,1))-1\n",
    "b, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.07289959]]), (1, 1))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward (linear) pass\n",
    "y = x*w +b\n",
    "y, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define activation function\n",
    "sigmoid = lambda x: 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.25485205]]), (1, 1))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward (non-linear) pass\n",
    "y = sigmoid(x*w +b)\n",
    "y, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.25485205]]), (1, 1))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when we will use vectors and matrices\n",
    "# the mul (*) operation is replaced with dot product\n",
    "y = sigmoid(x.dot(w) +b)\n",
    "y, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "example with multiple input nodes (features) output nodes (classes/...)\n",
    "still using a single example\n",
    "'''\n",
    "n_input = 3\n",
    "n_output = 2\n",
    "\n",
    "n_examples = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.16595599,  0.44064899, -0.99977125]]), (1, 3))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 2 * np.random.random((n_examples, n_input)) - 1\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.39533485, -0.70648822],\n",
       "        [-0.81532281, -0.62747958],\n",
       "        [-0.30887855, -0.20646505]]),\n",
       " (3, 2))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights - now use upper-case W because is a matrix\n",
    "# weights shape should match the input and output of the x*W result\n",
    "W = 2 * np.random.random((n_input, n_output)) - 1\n",
    "W, W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.07763347, -0.16161097]]), (1, 2))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bias is with the shape of a single output example\n",
    "b = 2 * np.random.random((1, n_output)) - 1\n",
    "b, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.52317797, 0.47141983]]), (1, 2))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass\n",
    "y = sigmoid(x.dot(W) +b)\n",
    "y, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple examples\n",
    "n_input = 3\n",
    "n_output = 2\n",
    "\n",
    "n_examples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.16595599,  0.44064899, -0.99977125],\n",
       "        [-0.39533485, -0.70648822, -0.81532281],\n",
       "        [-0.62747958, -0.30887855, -0.20646505],\n",
       "        [ 0.07763347, -0.16161097,  0.370439  ],\n",
       "        [-0.5910955 ,  0.75623487, -0.94522481]]),\n",
       " (5, 3))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs are now in matrix, so use upper-case X\n",
    "# each row is an example\n",
    "X = 2 * np.random.random((n_examples, n_input)) - 1\n",
    "X, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.34093502, -0.1653904 ],\n",
       "        [ 0.11737966, -0.71922612],\n",
       "        [-0.60379702,  0.60148914]]),\n",
       " (3, 2))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights shape does not depend on the number of examples\n",
    "# only on the sape of a single input and output example\n",
    "W = 2 * np.random.random((n_input, n_output)) - 1\n",
    "W, W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.16595599,  0.44064899]]), (1, 2))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bias is with the shape of a single output example - still lower-case b because is a vector\n",
    "b = 2 * np.random.random((1, n_output)) - 1\n",
    "b, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8227841  0.22028919]] (1, 2)\n",
      "[[0.8227841  0.22028919]\n",
      " [0.77049384 0.4279916 ]\n",
      " [0.69232262 0.45725323]\n",
      " [0.67268437 0.48826675]\n",
      " [0.80130784 0.19975338]] (5, 2)\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "# the same code of single example - dot product \"magic\"\n",
    "# the dot product is applied to each x example in X\n",
    "\n",
    "# output is also a matrix - so now use upper-case Y\n",
    "\n",
    "y0 = sigmoid(X[0].dot(W) +b)\n",
    "Y = sigmoid(X.dot(W) +b)\n",
    "print(y0, y0.shape)\n",
    "print(Y, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a hidden layer\n",
    "n_input = 3\n",
    "n_hidden = 4\n",
    "n_output = 2\n",
    "\n",
    "n_examples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.16595599,  0.44064899, -0.99977125],\n",
       "        [-0.39533485, -0.70648822, -0.81532281],\n",
       "        [-0.62747958, -0.30887855, -0.20646505],\n",
       "        [ 0.07763347, -0.16161097,  0.370439  ],\n",
       "        [-0.5910955 ,  0.75623487, -0.94522481]]),\n",
       " (5, 3))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = 2 * np.random.random((n_examples, n_input)) - 1\n",
    "X, X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.34093502, -0.1653904 ,  0.11737966],\n",
       "        [-0.71922612, -0.60379702,  0.60148914],\n",
       "        [ 0.93652315, -0.37315164,  0.38464523],\n",
       "        [ 0.7527783 ,  0.78921333, -0.82991158],\n",
       "        [-0.92189043, -0.66033916,  0.75628501]]),\n",
       " (5, 3))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hidden layer shape depend on its number of nodes\n",
    "# AND on the number of examples\n",
    "\n",
    "H = 2 * np.random.random((n_examples, n_input)) - 1\n",
    "H, H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now there are multiple weight matrices and bias vectors\n",
    "\n",
    "# input to hidden\n",
    "Wih = 2 * np.random.random((n_input, n_hidden)) - 1\n",
    "bih = 2 * np.random.random((1, n_hidden)) - 1\n",
    "\n",
    "# hidden to output\n",
    "Who = 2 * np.random.random((n_hidden, n_output)) - 1\n",
    "bho = 2 * np.random.random((1, n_output)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.49028916, 0.15646898],\n",
       "        [0.48967728, 0.15585518],\n",
       "        [0.44143544, 0.15017967],\n",
       "        [0.32213702, 0.16615516],\n",
       "        [0.50568541, 0.14845111]]),\n",
       " (5, 2))"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass through all layers\n",
    "H = sigmoid(X.dot(Wih) + bih)\n",
    "Y = sigmoid(H.dot(Who) + bho)\n",
    "\n",
    "Y, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x: 1/(1+np.exp(-x))\n",
    "sigmoid_backward = lambda x: sigmoid(x) * (1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 3\n",
    "n_hidden = 4\n",
    "n_output = 2\n",
    "\n",
    "n_examples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for simplicity we won't use biases this time\n",
    "\n",
    "X = np.random.random((n_examples, n_input)) > 0.5\n",
    "H = 2 * np.random.random((n_examples, n_input)) - 1\n",
    "Y = np.zeros((n_examples, n_output))  # the actual outputs\n",
    "\n",
    "# input to hidden\n",
    "Wih = 2 * np.random.random((n_input, n_hidden)) - 1\n",
    "\n",
    "# hidden to output\n",
    "Who = 2 * np.random.random((n_hidden, n_output)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "H = sigmoid(X.dot(Wih))\n",
    "Yp = sigmoid(H.dot(Who))  # output predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = Y - Yp  # per example"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
